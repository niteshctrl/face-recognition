{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "53 Face Recognition using Keras and OpenCV.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niteshctrl/face_recognition/blob/main/53_Face_Recognition_using_Keras_and_OpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQt0M_Odf6TV"
      },
      "source": [
        "# Importing Libraries\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "from keras import Model\n",
        "from keras.applications import VGG16\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y5PCFvzgIVN",
        "outputId": "b1ff7590-6a2b-42ef-a59f-a89d80e67e9b"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eg10vsVhtcy",
        "outputId": "3549d843-12df-46b6-fde2-171c8009fa1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uITG0TYXiLnN",
        "outputId": "7f08984c-565f-4a82-de63-6addcbd032ab"
      },
      "source": [
        "!unzip /content/gdrive/MyDrive/face_data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/MyDrive/face_data.zip\n",
            "   creating: face_data/\n",
            "   creating: face_data/train/\n",
            "   creating: face_data/train/nita/\n",
            "  inflating: face_data/train/nita/19.jpg  \n",
            "  inflating: face_data/train/nita/20.jpg  \n",
            "  inflating: face_data/train/nita/21.jpg  \n",
            "  inflating: face_data/train/nita/22.jpg  \n",
            "  inflating: face_data/train/nita/23.jpg  \n",
            "  inflating: face_data/train/nita/24.jpg  \n",
            "  inflating: face_data/train/nita/25.jpg  \n",
            "  inflating: face_data/train/nita/26.jpg  \n",
            "  inflating: face_data/train/nita/27.jpg  \n",
            "  inflating: face_data/train/nita/28.jpg  \n",
            "  inflating: face_data/train/nita/29.jpg  \n",
            "  inflating: face_data/train/nita/30.jpg  \n",
            "  inflating: face_data/train/nita/31.jpg  \n",
            "  inflating: face_data/train/nita/32.jpg  \n",
            "  inflating: face_data/train/nita/33.jpg  \n",
            "  inflating: face_data/train/nita/34.jpg  \n",
            "  inflating: face_data/train/nita/35.jpg  \n",
            "  inflating: face_data/train/nita/36.jpg  \n",
            "  inflating: face_data/train/nita/37.jpg  \n",
            "  inflating: face_data/train/nita/38.jpg  \n",
            "  inflating: face_data/train/nita/39.jpg  \n",
            "  inflating: face_data/train/nita/40.jpg  \n",
            "  inflating: face_data/train/nita/41.jpg  \n",
            "  inflating: face_data/train/nita/42.jpg  \n",
            "  inflating: face_data/train/nita/43.jpg  \n",
            "  inflating: face_data/train/nita/44.jpg  \n",
            "  inflating: face_data/train/nita/45.jpg  \n",
            "  inflating: face_data/train/nita/46.jpg  \n",
            "  inflating: face_data/train/nita/47.jpg  \n",
            "  inflating: face_data/train/nita/48.jpg  \n",
            "  inflating: face_data/train/nita/49.jpg  \n",
            "  inflating: face_data/train/nita/50.jpg  \n",
            "  inflating: face_data/train/nita/51.jpg  \n",
            "  inflating: face_data/train/nita/52.jpg  \n",
            "  inflating: face_data/train/nita/53.jpg  \n",
            "  inflating: face_data/train/nita/54.jpg  \n",
            "  inflating: face_data/train/nita/55.jpg  \n",
            "  inflating: face_data/train/nita/56.jpg  \n",
            "  inflating: face_data/train/nita/57.jpg  \n",
            "  inflating: face_data/train/nita/58.jpg  \n",
            "  inflating: face_data/train/nita/59.jpg  \n",
            "  inflating: face_data/train/nita/60.jpg  \n",
            "  inflating: face_data/train/nita/61.jpg  \n",
            "  inflating: face_data/train/nita/62.jpg  \n",
            "  inflating: face_data/train/nita/63.jpg  \n",
            "  inflating: face_data/train/nita/64.jpg  \n",
            "  inflating: face_data/train/nita/65.jpg  \n",
            "  inflating: face_data/train/nita/66.jpg  \n",
            "  inflating: face_data/train/nita/67.jpg  \n",
            "  inflating: face_data/train/nita/68.jpg  \n",
            "  inflating: face_data/train/nita/69.jpg  \n",
            "  inflating: face_data/train/nita/70.jpg  \n",
            "  inflating: face_data/train/nita/71.jpg  \n",
            "  inflating: face_data/train/nita/72.jpg  \n",
            "  inflating: face_data/train/nita/73.jpg  \n",
            "  inflating: face_data/train/nita/74.jpg  \n",
            "  inflating: face_data/train/nita/75.jpg  \n",
            "  inflating: face_data/train/nita/76.jpg  \n",
            "  inflating: face_data/train/nita/77.jpg  \n",
            "  inflating: face_data/train/nita/78.jpg  \n",
            "  inflating: face_data/train/nita/79.jpg  \n",
            "  inflating: face_data/train/nita/80.jpg  \n",
            "  inflating: face_data/train/nita/81.jpg  \n",
            "  inflating: face_data/train/nita/82.jpg  \n",
            "  inflating: face_data/train/nita/83.jpg  \n",
            "  inflating: face_data/train/nita/84.jpg  \n",
            "  inflating: face_data/train/nita/85.jpg  \n",
            "  inflating: face_data/train/nita/86.jpg  \n",
            "  inflating: face_data/train/nita/87.jpg  \n",
            "  inflating: face_data/train/nita/88.jpg  \n",
            "  inflating: face_data/train/nita/89.jpg  \n",
            "  inflating: face_data/train/nita/90.jpg  \n",
            "  inflating: face_data/train/nita/91.jpg  \n",
            "  inflating: face_data/train/nita/92.jpg  \n",
            "  inflating: face_data/train/nita/93.jpg  \n",
            "  inflating: face_data/train/nita/94.jpg  \n",
            "  inflating: face_data/train/nita/95.jpg  \n",
            "  inflating: face_data/train/nita/96.jpg  \n",
            "  inflating: face_data/train/nita/97.jpg  \n",
            "  inflating: face_data/train/nita/98.jpg  \n",
            "  inflating: face_data/train/nita/99.jpg  \n",
            "  inflating: face_data/train/nita/100.jpg  \n",
            "  inflating: face_data/train/nita/101.jpg  \n",
            "  inflating: face_data/train/nita/102.jpg  \n",
            "  inflating: face_data/train/nita/103.jpg  \n",
            "  inflating: face_data/train/nita/104.jpg  \n",
            "  inflating: face_data/train/nita/105.jpg  \n",
            "  inflating: face_data/train/nita/106.jpg  \n",
            "  inflating: face_data/train/nita/107.jpg  \n",
            "  inflating: face_data/train/nita/108.jpg  \n",
            "  inflating: face_data/train/nita/109.jpg  \n",
            "  inflating: face_data/train/nita/110.jpg  \n",
            "  inflating: face_data/train/nita/111.jpg  \n",
            "  inflating: face_data/train/nita/112.jpg  \n",
            "  inflating: face_data/train/nita/113.jpg  \n",
            "  inflating: face_data/train/nita/114.jpg  \n",
            "  inflating: face_data/train/nita/115.jpg  \n",
            "  inflating: face_data/train/nita/116.jpg  \n",
            "  inflating: face_data/train/nita/117.jpg  \n",
            "  inflating: face_data/train/nita/118.jpg  \n",
            "  inflating: face_data/train/nita/119.jpg  \n",
            "  inflating: face_data/train/nita/120.jpg  \n",
            "  inflating: face_data/train/nita/121.jpg  \n",
            "  inflating: face_data/train/nita/122.jpg  \n",
            "  inflating: face_data/train/nita/123.jpg  \n",
            "  inflating: face_data/train/nita/124.jpg  \n",
            "  inflating: face_data/train/nita/125.jpg  \n",
            "  inflating: face_data/train/nita/126.jpg  \n",
            "  inflating: face_data/train/nita/127.jpg  \n",
            "  inflating: face_data/train/nita/128.jpg  \n",
            "  inflating: face_data/train/nita/129.jpg  \n",
            "  inflating: face_data/train/nita/130.jpg  \n",
            "  inflating: face_data/train/nita/131.jpg  \n",
            "  inflating: face_data/train/nita/132.jpg  \n",
            "  inflating: face_data/train/nita/133.jpg  \n",
            "  inflating: face_data/train/nita/134.jpg  \n",
            "  inflating: face_data/train/nita/135.jpg  \n",
            "  inflating: face_data/train/nita/136.jpg  \n",
            "  inflating: face_data/train/nita/137.jpg  \n",
            "  inflating: face_data/train/nita/138.jpg  \n",
            "  inflating: face_data/train/nita/139.jpg  \n",
            "  inflating: face_data/train/nita/140.jpg  \n",
            "  inflating: face_data/train/nita/141.jpg  \n",
            "  inflating: face_data/train/nita/142.jpg  \n",
            "  inflating: face_data/train/nita/143.jpg  \n",
            "  inflating: face_data/train/nita/144.jpg  \n",
            "  inflating: face_data/train/nita/145.jpg  \n",
            "  inflating: face_data/train/nita/146.jpg  \n",
            "  inflating: face_data/train/nita/147.jpg  \n",
            "  inflating: face_data/train/nita/148.jpg  \n",
            "  inflating: face_data/train/nita/149.jpg  \n",
            "  inflating: face_data/train/nita/150.jpg  \n",
            "  inflating: face_data/train/nita/151.jpg  \n",
            "  inflating: face_data/train/nita/152.jpg  \n",
            "  inflating: face_data/train/nita/153.jpg  \n",
            "  inflating: face_data/train/nita/154.jpg  \n",
            "  inflating: face_data/train/nita/155.jpg  \n",
            "  inflating: face_data/train/nita/156.jpg  \n",
            "  inflating: face_data/train/nita/157.jpg  \n",
            "  inflating: face_data/train/nita/158.jpg  \n",
            "  inflating: face_data/train/nita/159.jpg  \n",
            "  inflating: face_data/train/nita/160.jpg  \n",
            "  inflating: face_data/train/nita/161.jpg  \n",
            "  inflating: face_data/train/nita/162.jpg  \n",
            "  inflating: face_data/train/nita/163.jpg  \n",
            "  inflating: face_data/train/nita/164.jpg  \n",
            "  inflating: face_data/train/nita/165.jpg  \n",
            "  inflating: face_data/train/nita/166.jpg  \n",
            "  inflating: face_data/train/nita/167.jpg  \n",
            "  inflating: face_data/train/nita/168.jpg  \n",
            "  inflating: face_data/train/nita/169.jpg  \n",
            "  inflating: face_data/train/nita/170.jpg  \n",
            "  inflating: face_data/train/nita/171.jpg  \n",
            "  inflating: face_data/train/nita/172.jpg  \n",
            "  inflating: face_data/train/nita/173.jpg  \n",
            "  inflating: face_data/train/nita/174.jpg  \n",
            "  inflating: face_data/train/nita/175.jpg  \n",
            "  inflating: face_data/train/nita/176.jpg  \n",
            "  inflating: face_data/train/nita/177.jpg  \n",
            "  inflating: face_data/train/nita/178.jpg  \n",
            "  inflating: face_data/train/nita/179.jpg  \n",
            "  inflating: face_data/train/nita/180.jpg  \n",
            "   creating: face_data/train/nitesh/\n",
            "  inflating: face_data/train/nitesh/19.jpg  \n",
            "  inflating: face_data/train/nitesh/20.jpg  \n",
            "  inflating: face_data/train/nitesh/21.jpg  \n",
            "  inflating: face_data/train/nitesh/22.jpg  \n",
            "  inflating: face_data/train/nitesh/23.jpg  \n",
            "  inflating: face_data/train/nitesh/24.jpg  \n",
            "  inflating: face_data/train/nitesh/25.jpg  \n",
            "  inflating: face_data/train/nitesh/26.jpg  \n",
            "  inflating: face_data/train/nitesh/27.jpg  \n",
            "  inflating: face_data/train/nitesh/28.jpg  \n",
            "  inflating: face_data/train/nitesh/29.jpg  \n",
            "  inflating: face_data/train/nitesh/30.jpg  \n",
            "  inflating: face_data/train/nitesh/31.jpg  \n",
            "  inflating: face_data/train/nitesh/32.jpg  \n",
            "  inflating: face_data/train/nitesh/33.jpg  \n",
            "  inflating: face_data/train/nitesh/34.jpg  \n",
            "  inflating: face_data/train/nitesh/35.jpg  \n",
            "  inflating: face_data/train/nitesh/36.jpg  \n",
            "  inflating: face_data/train/nitesh/37.jpg  \n",
            "  inflating: face_data/train/nitesh/38.jpg  \n",
            "  inflating: face_data/train/nitesh/39.jpg  \n",
            "  inflating: face_data/train/nitesh/40.jpg  \n",
            "  inflating: face_data/train/nitesh/41.jpg  \n",
            "  inflating: face_data/train/nitesh/42.jpg  \n",
            "  inflating: face_data/train/nitesh/43.jpg  \n",
            "  inflating: face_data/train/nitesh/44.jpg  \n",
            "  inflating: face_data/train/nitesh/45.jpg  \n",
            "  inflating: face_data/train/nitesh/46.jpg  \n",
            "  inflating: face_data/train/nitesh/47.jpg  \n",
            "  inflating: face_data/train/nitesh/48.jpg  \n",
            "  inflating: face_data/train/nitesh/49.jpg  \n",
            "  inflating: face_data/train/nitesh/50.jpg  \n",
            "  inflating: face_data/train/nitesh/51.jpg  \n",
            "  inflating: face_data/train/nitesh/52.jpg  \n",
            "  inflating: face_data/train/nitesh/53.jpg  \n",
            "  inflating: face_data/train/nitesh/54.jpg  \n",
            "  inflating: face_data/train/nitesh/55.jpg  \n",
            "  inflating: face_data/train/nitesh/56.jpg  \n",
            "  inflating: face_data/train/nitesh/57.jpg  \n",
            "  inflating: face_data/train/nitesh/58.jpg  \n",
            "  inflating: face_data/train/nitesh/59.jpg  \n",
            "  inflating: face_data/train/nitesh/60.jpg  \n",
            "  inflating: face_data/train/nitesh/61.jpg  \n",
            "  inflating: face_data/train/nitesh/62.jpg  \n",
            "  inflating: face_data/train/nitesh/63.jpg  \n",
            "  inflating: face_data/train/nitesh/64.jpg  \n",
            "  inflating: face_data/train/nitesh/65.jpg  \n",
            "  inflating: face_data/train/nitesh/66.jpg  \n",
            "  inflating: face_data/train/nitesh/67.jpg  \n",
            "  inflating: face_data/train/nitesh/68.jpg  \n",
            "  inflating: face_data/train/nitesh/69.jpg  \n",
            "  inflating: face_data/train/nitesh/70.jpg  \n",
            "  inflating: face_data/train/nitesh/71.jpg  \n",
            "  inflating: face_data/train/nitesh/72.jpg  \n",
            "  inflating: face_data/train/nitesh/73.jpg  \n",
            "  inflating: face_data/train/nitesh/74.jpg  \n",
            "  inflating: face_data/train/nitesh/75.jpg  \n",
            "  inflating: face_data/train/nitesh/76.jpg  \n",
            "  inflating: face_data/train/nitesh/77.jpg  \n",
            "  inflating: face_data/train/nitesh/78.jpg  \n",
            "  inflating: face_data/train/nitesh/79.jpg  \n",
            "  inflating: face_data/train/nitesh/80.jpg  \n",
            "  inflating: face_data/train/nitesh/81.jpg  \n",
            "  inflating: face_data/train/nitesh/82.jpg  \n",
            "  inflating: face_data/train/nitesh/83.jpg  \n",
            "  inflating: face_data/train/nitesh/84.jpg  \n",
            "  inflating: face_data/train/nitesh/85.jpg  \n",
            "  inflating: face_data/train/nitesh/86.jpg  \n",
            "  inflating: face_data/train/nitesh/87.jpg  \n",
            "  inflating: face_data/train/nitesh/88.jpg  \n",
            "  inflating: face_data/train/nitesh/89.jpg  \n",
            "  inflating: face_data/train/nitesh/90.jpg  \n",
            "  inflating: face_data/train/nitesh/91.jpg  \n",
            "  inflating: face_data/train/nitesh/92.jpg  \n",
            "  inflating: face_data/train/nitesh/93.jpg  \n",
            "  inflating: face_data/train/nitesh/94.jpg  \n",
            "  inflating: face_data/train/nitesh/95.jpg  \n",
            "  inflating: face_data/train/nitesh/96.jpg  \n",
            "  inflating: face_data/train/nitesh/97.jpg  \n",
            "  inflating: face_data/train/nitesh/98.jpg  \n",
            "  inflating: face_data/train/nitesh/99.jpg  \n",
            "  inflating: face_data/train/nitesh/100.jpg  \n",
            "  inflating: face_data/train/nitesh/101.jpg  \n",
            "  inflating: face_data/train/nitesh/102.jpg  \n",
            "  inflating: face_data/train/nitesh/103.jpg  \n",
            "  inflating: face_data/train/nitesh/104.jpg  \n",
            "  inflating: face_data/train/nitesh/105.jpg  \n",
            "  inflating: face_data/train/nitesh/106.jpg  \n",
            "  inflating: face_data/train/nitesh/107.jpg  \n",
            "  inflating: face_data/train/nitesh/108.jpg  \n",
            "  inflating: face_data/train/nitesh/109.jpg  \n",
            "  inflating: face_data/train/nitesh/110.jpg  \n",
            "  inflating: face_data/train/nitesh/111.jpg  \n",
            "  inflating: face_data/train/nitesh/112.jpg  \n",
            "  inflating: face_data/train/nitesh/113.jpg  \n",
            "  inflating: face_data/train/nitesh/114.jpg  \n",
            "  inflating: face_data/train/nitesh/115.jpg  \n",
            "  inflating: face_data/train/nitesh/116.jpg  \n",
            "  inflating: face_data/train/nitesh/117.jpg  \n",
            "  inflating: face_data/train/nitesh/118.jpg  \n",
            "  inflating: face_data/train/nitesh/119.jpg  \n",
            "  inflating: face_data/train/nitesh/120.jpg  \n",
            "  inflating: face_data/train/nitesh/121.jpg  \n",
            "  inflating: face_data/train/nitesh/122.jpg  \n",
            "  inflating: face_data/train/nitesh/123.jpg  \n",
            "  inflating: face_data/train/nitesh/124.jpg  \n",
            "  inflating: face_data/train/nitesh/125.jpg  \n",
            "  inflating: face_data/train/nitesh/126.jpg  \n",
            "  inflating: face_data/train/nitesh/127.jpg  \n",
            "  inflating: face_data/train/nitesh/128.jpg  \n",
            "  inflating: face_data/train/nitesh/129.jpg  \n",
            "  inflating: face_data/train/nitesh/130.jpg  \n",
            "  inflating: face_data/train/nitesh/131.jpg  \n",
            "  inflating: face_data/train/nitesh/132.jpg  \n",
            "  inflating: face_data/train/nitesh/133.jpg  \n",
            "  inflating: face_data/train/nitesh/134.jpg  \n",
            "  inflating: face_data/train/nitesh/135.jpg  \n",
            "  inflating: face_data/train/nitesh/136.jpg  \n",
            "  inflating: face_data/train/nitesh/137.jpg  \n",
            "  inflating: face_data/train/nitesh/138.jpg  \n",
            "  inflating: face_data/train/nitesh/139.jpg  \n",
            "  inflating: face_data/train/nitesh/140.jpg  \n",
            "  inflating: face_data/train/nitesh/141.jpg  \n",
            "  inflating: face_data/train/nitesh/142.jpg  \n",
            "  inflating: face_data/train/nitesh/143.jpg  \n",
            "  inflating: face_data/train/nitesh/144.jpg  \n",
            "  inflating: face_data/train/nitesh/145.jpg  \n",
            "  inflating: face_data/train/nitesh/146.jpg  \n",
            "  inflating: face_data/train/nitesh/147.jpg  \n",
            "  inflating: face_data/train/nitesh/148.jpg  \n",
            "  inflating: face_data/train/nitesh/149.jpg  \n",
            "  inflating: face_data/train/nitesh/150.jpg  \n",
            "  inflating: face_data/train/nitesh/151.jpg  \n",
            "  inflating: face_data/train/nitesh/152.jpg  \n",
            "  inflating: face_data/train/nitesh/153.jpg  \n",
            "  inflating: face_data/train/nitesh/154.jpg  \n",
            "  inflating: face_data/train/nitesh/155.jpg  \n",
            "  inflating: face_data/train/nitesh/156.jpg  \n",
            "  inflating: face_data/train/nitesh/157.jpg  \n",
            "  inflating: face_data/train/nitesh/158.jpg  \n",
            "  inflating: face_data/train/nitesh/159.jpg  \n",
            "  inflating: face_data/train/nitesh/160.jpg  \n",
            "  inflating: face_data/train/nitesh/161.jpg  \n",
            "  inflating: face_data/train/nitesh/162.jpg  \n",
            "  inflating: face_data/train/nitesh/163.jpg  \n",
            "  inflating: face_data/train/nitesh/164.jpg  \n",
            "  inflating: face_data/train/nitesh/165.jpg  \n",
            "  inflating: face_data/train/nitesh/166.jpg  \n",
            "  inflating: face_data/train/nitesh/167.jpg  \n",
            "  inflating: face_data/train/nitesh/168.jpg  \n",
            "  inflating: face_data/train/nitesh/169.jpg  \n",
            "  inflating: face_data/train/nitesh/170.jpg  \n",
            "  inflating: face_data/train/nitesh/171.jpg  \n",
            "  inflating: face_data/train/nitesh/172.jpg  \n",
            "  inflating: face_data/train/nitesh/173.jpg  \n",
            "  inflating: face_data/train/nitesh/174.jpg  \n",
            "  inflating: face_data/train/nitesh/175.jpg  \n",
            "  inflating: face_data/train/nitesh/176.jpg  \n",
            "  inflating: face_data/train/nitesh/177.jpg  \n",
            "  inflating: face_data/train/nitesh/178.jpg  \n",
            "  inflating: face_data/train/nitesh/179.jpg  \n",
            "  inflating: face_data/train/nitesh/180.jpg  \n",
            "   creating: face_data/val/\n",
            "   creating: face_data/val/nitesh/\n",
            "  inflating: face_data/val/nitesh/1.jpg  \n",
            "  inflating: face_data/val/nitesh/2.jpg  \n",
            "  inflating: face_data/val/nitesh/3.jpg  \n",
            "  inflating: face_data/val/nitesh/4.jpg  \n",
            "  inflating: face_data/val/nitesh/5.jpg  \n",
            "  inflating: face_data/val/nitesh/6.jpg  \n",
            "  inflating: face_data/val/nitesh/7.jpg  \n",
            "  inflating: face_data/val/nitesh/8.jpg  \n",
            "  inflating: face_data/val/nitesh/9.jpg  \n",
            "  inflating: face_data/val/nitesh/10.jpg  \n",
            "  inflating: face_data/val/nitesh/11.jpg  \n",
            "  inflating: face_data/val/nitesh/12.jpg  \n",
            "  inflating: face_data/val/nitesh/13.jpg  \n",
            "  inflating: face_data/val/nitesh/14.jpg  \n",
            "  inflating: face_data/val/nitesh/15.jpg  \n",
            "  inflating: face_data/val/nitesh/16.jpg  \n",
            "  inflating: face_data/val/nitesh/17.jpg  \n",
            "  inflating: face_data/val/nitesh/18.jpg  \n",
            "  inflating: face_data/val/nitesh/181.jpg  \n",
            "  inflating: face_data/val/nitesh/182.jpg  \n",
            "  inflating: face_data/val/nitesh/183.jpg  \n",
            "  inflating: face_data/val/nitesh/184.jpg  \n",
            "  inflating: face_data/val/nitesh/185.jpg  \n",
            "  inflating: face_data/val/nitesh/186.jpg  \n",
            "  inflating: face_data/val/nitesh/187.jpg  \n",
            "  inflating: face_data/val/nitesh/188.jpg  \n",
            "  inflating: face_data/val/nitesh/189.jpg  \n",
            "  inflating: face_data/val/nitesh/190.jpg  \n",
            "  inflating: face_data/val/nitesh/191.jpg  \n",
            "  inflating: face_data/val/nitesh/192.jpg  \n",
            "  inflating: face_data/val/nitesh/193.jpg  \n",
            "  inflating: face_data/val/nitesh/194.jpg  \n",
            "  inflating: face_data/val/nitesh/195.jpg  \n",
            "  inflating: face_data/val/nitesh/196.jpg  \n",
            "  inflating: face_data/val/nitesh/197.jpg  \n",
            "  inflating: face_data/val/nitesh/198.jpg  \n",
            "  inflating: face_data/val/nitesh/199.jpg  \n",
            "  inflating: face_data/val/nitesh/200.jpg  \n",
            "   creating: face_data/val/nita/\n",
            "  inflating: face_data/val/nita/1.jpg  \n",
            "  inflating: face_data/val/nita/2.jpg  \n",
            "  inflating: face_data/val/nita/3.jpg  \n",
            "  inflating: face_data/val/nita/4.jpg  \n",
            "  inflating: face_data/val/nita/5.jpg  \n",
            "  inflating: face_data/val/nita/6.jpg  \n",
            "  inflating: face_data/val/nita/7.jpg  \n",
            "  inflating: face_data/val/nita/8.jpg  \n",
            "  inflating: face_data/val/nita/9.jpg  \n",
            "  inflating: face_data/val/nita/10.jpg  \n",
            "  inflating: face_data/val/nita/11.jpg  \n",
            "  inflating: face_data/val/nita/12.jpg  \n",
            "  inflating: face_data/val/nita/13.jpg  \n",
            "  inflating: face_data/val/nita/14.jpg  \n",
            "  inflating: face_data/val/nita/15.jpg  \n",
            "  inflating: face_data/val/nita/16.jpg  \n",
            "  inflating: face_data/val/nita/17.jpg  \n",
            "  inflating: face_data/val/nita/18.jpg  \n",
            "  inflating: face_data/val/nita/181.jpg  \n",
            "  inflating: face_data/val/nita/182.jpg  \n",
            "  inflating: face_data/val/nita/183.jpg  \n",
            "  inflating: face_data/val/nita/184.jpg  \n",
            "  inflating: face_data/val/nita/185.jpg  \n",
            "  inflating: face_data/val/nita/186.jpg  \n",
            "  inflating: face_data/val/nita/187.jpg  \n",
            "  inflating: face_data/val/nita/188.jpg  \n",
            "  inflating: face_data/val/nita/189.jpg  \n",
            "  inflating: face_data/val/nita/190.jpg  \n",
            "  inflating: face_data/val/nita/191.jpg  \n",
            "  inflating: face_data/val/nita/192.jpg  \n",
            "  inflating: face_data/val/nita/193.jpg  \n",
            "  inflating: face_data/val/nita/194.jpg  \n",
            "  inflating: face_data/val/nita/195.jpg  \n",
            "  inflating: face_data/val/nita/196.jpg  \n",
            "  inflating: face_data/val/nita/197.jpg  \n",
            "  inflating: face_data/val/nita/198.jpg  \n",
            "  inflating: face_data/val/nita/199.jpg  \n",
            "  inflating: face_data/val/nita/200.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpA8OBeff6TZ"
      },
      "source": [
        "# Face detector model\n",
        "\n",
        "face_detector = cv2.CascadeClassifier('haarcascade.xml')\n",
        "\n",
        "data_dir = 'face_data/'\n",
        "image_size = [224,224]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1DOi-LVf6Ta"
      },
      "source": [
        "faces = face_detector.detectMultiScale(cv2.imread('file.jpg'), 1.1, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5TVU7JVf6Tb"
      },
      "source": [
        "# Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb_WF8Vhf6Tb",
        "outputId": "a901b9c1-9008-48b5-9b75-8b31bbe95f3e"
      },
      "source": [
        "print(\"Enter the name of the person to collect face data\")\n",
        "name = input()\n",
        "pwd = !pwd\n",
        "\n",
        "\n",
        "# Creating directory for storing collected data\n",
        "\n",
        "if not os.path.isdir(data_dir + name):\n",
        "    os.mkdir(data_dir + name)\n",
        "\n",
        "\n",
        "# Initialize the webcam\n",
        "vid = cv2.VideoCapture(0)\n",
        "count = 200 # How many frames to collect for training\n",
        "c = 0\n",
        "\n",
        "\n",
        "while True:\n",
        "    ret, frame = vid.read()\n",
        "    faces = face_detector.detectMultiScale(frame, 1.1, 4)\n",
        "    \n",
        "    if len(faces) == 0:\n",
        "        continue\n",
        "    c = c + 1\n",
        "    if c > 200:\n",
        "        break\n",
        "    \n",
        "    for (x, y, w, h) in faces:\n",
        "        cropped_face = cv2.resize(frame[y:y+h+10, x:x+w+10], image_size)\n",
        "    cv2.imshow('Video', cropped_face)\n",
        "    cv2.imwrite(data_dir + name + '/' + str(c) + '.jpg', cropped_face)\n",
        "    \n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "vid.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the name of the person to collect face data\n",
            "nita\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO0oA3vTf6Td"
      },
      "source": [
        "# Modelling and Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHTMbyF8f6Te"
      },
      "source": [
        "num_classes = glob.glob('face_data/train/*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKcJ2tNDi6m9",
        "outputId": "1a8282f2-6f5b-4dad-d79b-6ff69450a845"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['face_data/train/nita', 'face_data/train/nitesh']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjtCZ01vf6Te",
        "outputId": "d0dfccea-61e3-451d-989b-c1ec9d5b6532"
      },
      "source": [
        "model = VGG16(include_top=False, \n",
        "              weights='imagenet',\n",
        "              input_shape=image_size + [3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyHBVZ5Tf6Tf"
      },
      "source": [
        "#Freeze the pretrained layers\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOvdK7-Ff6Tf"
      },
      "source": [
        "# Append the fully connected layers\n",
        "\n",
        "flatten_layer = Flatten()(model.output)\n",
        "dense1 = Dense(128, activation='relu')(flatten_layer)\n",
        "final_layer = Dense(len(num_classes), activation='sigmoid')(dense1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLrGgZ0cf6Tg",
        "outputId": "1c2b1ae2-06bd-47f8-e0da-5a93ac13d588"
      },
      "source": [
        "# Create final model object\n",
        "\n",
        "my_model = Model(inputs=model.input, outputs=final_layer)\n",
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 17,926,338\n",
            "Trainable params: 3,211,650\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctvV5P5Lf6Tg",
        "outputId": "bb24925f-a916-4c51-88c3-56e6c1ba138f"
      },
      "source": [
        "# Image Augmentation\n",
        "\n",
        "datagen_train = ImageDataGenerator(rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "                            zoom_range = 0.1, # Randomly zoom image \n",
        "                            horizontal_flip=True,  # randomly flip images\n",
        "                            brightness_range=[0.3,2],\n",
        "                            rescale = 1./255,\n",
        "                            validation_split=0)\n",
        "datagen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "iterator_train = datagen_train.flow_from_directory(data_dir+'/train', \n",
        "                                       target_size=(224,224),\n",
        "                                       batch_size=32,\n",
        "                                       class_mode='binary')\n",
        "\n",
        "iterator_val = datagen_val.flow_from_directory(data_dir+'/val', \n",
        "                                               target_size=(224,224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 324 images belonging to 2 classes.\n",
            "Found 76 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p4c0mPef6Th"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF14tIZnf6Ti"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "wq7LkwIvf6Ti",
        "outputId": "b0e79ec5-15c7-40cc-a8b0-21c7adc3a50e"
      },
      "source": [
        "# Fit the model and save losses to history variable\n",
        "\n",
        "filepath=\"my_model.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit(iterator_train,\n",
        "                    validation_data=iterator_val,\n",
        "                    epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-27e261cf5a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m history = model.fit(iterator_train,\n\u001b[1;32m      8\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterator_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     epochs=10)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [32,7,7,512] vs. [32,1]\n\t [[node binary_crossentropy/mul_1 (defined at <ipython-input-12-27e261cf5a4f>:9) ]] [Op:__inference_train_function_1202]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-3Pdctmf6Tj"
      },
      "source": [
        "# References\n",
        "\n",
        "1. [Face Detection in 2 Minutes using OpenCV & Python] https://towardsdatascience.com/face-detection-in-2-minutes-using-opencv-python-90f89d7c0f81\n",
        "\n",
        "2. [Python OpenCV: Capture Video from Camera] https://www.geeksforgeeks.org/python-opencv-capture-video-from-camera/\n",
        "\n",
        "3. [TensorFlow Core v2.5.0] https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
      ]
    }
  ]
}